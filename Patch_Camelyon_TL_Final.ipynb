{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Patch_Camelyon_TL_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GIc2zHvN2hMT",
        "-Eui8IE-Aywh"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cX1qQvG61bon"
      },
      "source": [
        "## Setup and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsFK1stdz_hB"
      },
      "source": [
        "!pip install tensorflow-io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms7wYCgYfYdV"
      },
      "source": [
        "!pip install --upgrade tensorflow-datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z_hDJO0GSvK"
      },
      "source": [
        "# Import NumPy to handle array's and Matplotlib for plotting loss curves\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "#Define random seed to avoid randomness to corrupt training\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(1)\n",
        "\n",
        "#Import tensorflow datasets\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Import TensorFlow and relevant Keras classes to setup the model\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers, datasets, optimizers\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "#import tensorflow_io as tfio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WOxgqvUC499"
      },
      "source": [
        "# Load the dataset, and create the train and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoRlGrAXpbOi"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = '/content/gdrive/My Drive/Patch_Camelyon_tfds/'\n",
        "\n",
        "data, info = tfds.load(\"patch_camelyon\", with_info=True, data_dir=root_path, shuffle_files=True)\n",
        "\n",
        "train_ds = data['train']\n",
        "valid_ds = data['validation']\n",
        "test_ds = data['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td-wqb1YDPw3"
      },
      "source": [
        "# Visualize some of the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkh6A4WugyTe"
      },
      "source": [
        "print(info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDJtsw4rUcXf"
      },
      "source": [
        "# Visualize data (our way, more efficient)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYd19yxmDSV9"
      },
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(15,15))\n",
        "for data in train_ds.take(16):\n",
        "  img = data[\"image\"]\n",
        "  label = data[\"label\"]\n",
        "  i += 1\n",
        "  plt.subplot(4,4,i)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "  plt.title(label.numpy())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfBI9-fGKyEy"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1arx8--g9v9V"
      },
      "source": [
        "def split_data(data):\n",
        "  return data[\"image\"], data[\"label\"]\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.map(split_data, num_parallel_calls=AUTOTUNE).shuffle(1024).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "valid_ds = valid_ds.map(split_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.map(split_data, num_parallel_calls=AUTOTUNE).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Define smaller datasets, to make the first tests\n",
        "# small_train_ds = train_ds.map(split_data, num_parallel_calls=AUTOTUNE).take(1024).cache().shuffle(1024).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "# small_valid_ds = valid_ds.map(split_data, num_parallel_calls=AUTOTUNE).take(1024).batch(BATCH_SIZE).cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AimyC2qkXphB"
      },
      "source": [
        "def random_brightness_layer(factor=0.4):\n",
        "  return layers.Lambda(lambda x: tf.image.random_brightness(x, factor))\n",
        "\n",
        "def random_hue_layer(factor=0.2):\n",
        "  return layers.Lambda(lambda x: tf.image.random_hue(x, factor))\n",
        "\n",
        "def random_saturation_layer(lower=0.8, upper=1.2):\n",
        "  return layers.Lambda(lambda x: tf.image.random_saturation(x, lower, upper))\n",
        "\n",
        "random_brightness_layer = random_brightness_layer()\n",
        "random_hue_layer = random_hue_layer()\n",
        "random_saturation_layer = random_saturation_layer()\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.experimental.preprocessing.RandomZoom((-0.125,0), fill_mode='reflect'),\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\",),\n",
        "  layers.experimental.preprocessing.RandomRotation((-0.5,0.5)),\n",
        "  layers.experimental.preprocessing.RandomContrast(0.4),\n",
        "  random_brightness_layer,\n",
        "  random_hue_layer,\n",
        "  random_saturation_layer\n",
        "], name=\"data_augmentation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRyf3McjLBfC"
      },
      "source": [
        "def show(image, label):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(int(label.numpy()))\n",
        "  plt.axis('off')\n",
        "\n",
        "#Show augmented images\n",
        "for image, label in train_ds.take(2):\n",
        "  image = data_augmentation(image)\n",
        "  show(image[0], label[0])\n",
        "  print(image[0].dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2s3psUtLIsq"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Ii2p6SO9Wy"
      },
      "source": [
        "#Take the model\n",
        "TLmodel = tf.keras.applications.VGG16(weights=\"imagenet\", include_top = False, input_shape=(96,96,3))\n",
        "\n",
        "#Print the summary and the number of layers\n",
        "# TLmodel.summary()\n",
        "# for i, layer in enumerate(TLmodel.layers):\n",
        "#   print(i, layer.name)\n",
        "\n",
        "#Now freeze the batch normalization layers\n",
        "for layer in TLmodel.layers[:]:\n",
        "  if \"bn\" in layer.name:\n",
        "    layer.trainable = False\n",
        "\n",
        "TLmodel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIc2zHvN2hMT"
      },
      "source": [
        "#Kernel visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw_XEdD-2gJK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "6afcfb01-c18d-48b7-8303-30c5f843eb7f"
      },
      "source": [
        "#Extract the weights, meaning the filters and the biases used by the convolution layers\n",
        "for layer in TLmodel.layers:\n",
        "  if \"conv\" in layer.name:\n",
        "    filters, biases = layer.get_weights()\n",
        "\n",
        "#Normalize the filters, so we can better visualize them\n",
        "f_min = filters.min()\n",
        "f_max = filters.max()\n",
        "\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "# plot first few filters\n",
        "n_filters, ix = 6, 1\n",
        "plt.figure(figsize=(15,15))\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\tfor j in range(3):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = plt.subplot(n_filters, 3, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tplt.imshow(f[:, :, j], cmap='gray')\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 18 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbpPV8Gns99i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "28324963-690b-4926-c510-5b1b8c1223ba"
      },
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "  print(i,layer.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_52\n",
            "1 block1_conv1\n",
            "2 block1_conv2\n",
            "3 block1_pool\n",
            "4 block2_conv1\n",
            "5 block2_conv2\n",
            "6 block2_pool\n",
            "7 block3_conv1\n",
            "8 block3_conv2\n",
            "9 block3_conv3\n",
            "10 block3_pool\n",
            "11 block4_conv1\n",
            "12 block4_conv2\n",
            "13 block4_conv3\n",
            "14 block4_pool\n",
            "15 block5_conv1\n",
            "16 block5_conv2\n",
            "17 block5_conv3\n",
            "18 block5_pool\n",
            "19 flatten_10\n",
            "20 dense_56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65cgicjZDGAR"
      },
      "source": [
        "# Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgddAxb5DFKi"
      },
      "source": [
        "#Define a functional model\n",
        "#Define the input\n",
        "input = Input((96,96,3))\n",
        "\n",
        "#First of all, data augmentation\n",
        "x = data_augmentation(input)\n",
        "\n",
        "#Insert the transfer learning model\n",
        "x = TLmodel(x, training = False)\n",
        "\n",
        "#\n",
        "x = keras.layers.GlobalMaxPooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "out = keras.layers.Dense(1, activation ='sigmoid')(x)\n",
        "\n",
        "#Define the new model, use as input the TLmodel one, and as output the single neuron dense layer for our task\n",
        "model = Model(inputs = input, outputs = out)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss = tf.keras.losses.BinaryCrossentropy(), metrics = [\"accuracy\"])\n",
        "\n",
        "#print summary and the number of layers\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8axulhvvY4OS"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAVRNUYk-aTp"
      },
      "source": [
        "#Define the folder where to save and load data and models\n",
        "folder = os.path.join(root_path,'models_NN','Info',\"DenseNetFinal1693\")                                                                                                                                                                \n",
        "savename = \"Pcam_TL/DenseNetFinal3.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1HXZoEwou5N"
      },
      "source": [
        "#Use the model checkpoint to save the model\n",
        "callbacks = [ModelCheckpoint(os.path.join(root_path,'models_NN',savename), save_best_only=True)]\n",
        "\n",
        "#Train\n",
        "history = model.fit(train_ds, validation_data = valid_ds, epochs = 30, callbacks = callbacks, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC4JT5oR_CFj"
      },
      "source": [
        "#Load the best model\n",
        "model = models.load_model(os.path.join(root_path,'models_NN',savename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VZ_bauhAQPz"
      },
      "source": [
        "#Evaluate the model on the test\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF7x8jkBN8Pf"
      },
      "source": [
        "#Evaluate and plot the graphs of accuracy and loss.\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "#Evaluate and plot the graphs of accuracy and loss.\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.grid()\n",
        "plt.savefig(os.path.join(folder,\"accuracy.png\"))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.savefig(os.path.join(folder,\"loss.png\"))\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "f = open(os.path.join(folder,\"info.txt\"), \"w\")\n",
        "best_epoch = np.argmin(val_loss)\n",
        "f.writelines(\"Best epoch: \" + str(best_epoch + 1) + \"\\n\")\n",
        "f.write(\"Training accuracy: \" + str(acc[best_epoch]) + \"\\n\")\n",
        "f.write(\"Validation accuracy: \" + str(val_acc[best_epoch]) + \"\\n\")\n",
        "f.write(\"Training loss: \" + str(loss[best_epoch]) + \"\\n\")\n",
        "f.write(\"Validation loss: \" + str(val_loss[best_epoch]) + \"\\n\\n\")\n",
        "f.write(\"Test accuracy: \" + str(test_accuracy) + \"\\n\")\n",
        "f.write(\"Test loss: \" + str(test_loss) + \"\\n\")\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Eui8IE-Aywh"
      },
      "source": [
        "# Hyperparameters tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy96JqTJs9kU"
      },
      "source": [
        "#Define the input of the functional model\n",
        "def model_builder(hp):\n",
        "  hp_l2_regularizer = hp.Choice('l2_regularizer', values = [1e-2, 1e-3, 1e-4]) \n",
        "  hp_units = hp.Choice('units', values = [32, 64, 128, 256, 512])\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 5e-3, 1e-3, 5e-4, 1e-4]) \n",
        "\n",
        "  input = Input((96,96,3))\n",
        "  #x = data_augmentation(input)\n",
        "  x = TLmodel.output\n",
        "\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dense(256, activation ='relu')(x)\n",
        "  x = tf.keras.layers.Batch_Normalization()(x)\n",
        "  out = tf.keras.layers.Dense(1, activation ='sigmoid')(x)\n",
        "\n",
        "  #Define the new model, use as input the TLmodel one, and as output the single neuron dense layer for our task\n",
        "  model = Model(inputs = TLmodel.input, outputs = out)\n",
        "\n",
        "  #Define the new model, use as input the TLmodel one, and as output the single neuron dense layer for our task\n",
        "  # model = Model(inputs = TLmodel.input, outputs = out)\n",
        "\n",
        "  #Compile the model\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(), loss = tf.keras.losses.BinaryCrossentropy(), metrics = [\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbuzQz_gA2uR"
      },
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective = 'val_loss', \n",
        "                     max_epochs = 10)   \n",
        "\n",
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "  def on_train_end(*args, **kwargs):\n",
        "    IPython.display.clear_output(wait = True)\n",
        "\n",
        "tuner.search(train_ds, epochs = 10, validation_data = valid_ds, callbacks = [ClearTrainingOutput()])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "Units: {best_hps.get('units')} \\n\n",
        "Optimal learning rate for the optimizer: {best_hps.get('learning_rate')} \\n\n",
        "L2 regularization factor: {best_hps.get('l2_regularizer')}\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}